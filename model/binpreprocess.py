# -*- coding: utf-8 -*-
"""BinPreprocess.ipynb

Automatically generated by Colaboratory.

### Install Packages
"""

import sys
!{sys.executable} -m pip install dfply
!{sys.executable} -m pip install wikipedia
!{sys.executable} -m pip install HTMLparser

"""### Import Library"""

import pandas as pd
import numpy as np
from dfply import *
from wikipedia import *
import re
import html.parser as hp
import requests
from bs4 import BeautifulSoup
import html

"""### Oscar (1962-2002)"""

!git clone https://github.com/floraxhuang/Oscar.git

# %cd Oscar
oscar_data = pd.read_csv('data_csv.csv')

oscar_data.tail()

#training oscar data, ranged from 1962 to 2002
oscars = (oscar_data >> mask(X.category=="BEST PICTURE") 
                >> mask(X.year < 2003)
                >> drop(["category"]) 
                >> rename(Year=X.year,Film=X.entity, Win=X.winner) )
booleanDictionary = {True: 'True', False: 'False'}
oscars["Win"] = oscars["Win"].map(booleanDictionary)
di_oscar = {"True": 1, "False": -1}
oscars = oscars.replace({"Win": di_oscar})
oscars = oscars.assign(Rater="Oscars")[["Rater","Film","Year","Win"]].reset_index(drop=True)

oscars.head()

"""### National Board of Review Award for Best Film (1962-2018)"""

nbra_url = requests.get("https://en.wikipedia.org/wiki/National_Board_of_Review_Award_for_Best_Film").text

nbra_soup = BeautifulSoup(nbra_url,"lxml")
table_classes = {"class": ["wikitable"]}
nbra_tables = nbra_soup.find_all("table", table_classes)

### Data of NBRA, Date Range 1962-2018
nbra_titles = []
for t in range(3,len(nbra_tables)):
  links = nbra_tables[t].findAll("td")
  for l in range(len(links)):
    if str(links[l]).startswith("<td><i><b>"):
      nbra_titles.append(html.unescape(str(links[l]).split("title=",1)[1].split(">",1)[1].split("<",1)[0]))
nbra_titles = nbra_titles[2::]

nbra_years = []
for t in range(3,len(nbra_tables)):
  links = nbra_tables[t].findAll("td")
  for l in range(len(links)):
    if str(links[l]).startswith('<td style="text-align:center'):
      nbra_years.append(html.unescape(str(links[l]).split(">",1)[1].split("<",1)[0]))
    elif str(links[l]).startswith('<td rowspan='):
      rep_time = str(links[l]).split('"',1)[1].split('"',1)[0]
      for t in range(int(rep_time)):
        nbra_years.append(html.unescape(str(links[l]).split(">",1)[1].split("<",1)[0]))
nbra_years = nbra_years[2::]

nbra = pd.DataFrame({'Film': nbra_titles, 'Year': nbra_years}).assign(Rater="NBRA").assign(Win=1)
nbra = nbra[["Rater","Film","Year","Win"]]

nbra.head()

nbra.tail()

"""### Satellite Award for Best Film (1996-2018)"""

sa_url = requests.get("https://en.wikipedia.org/wiki/Satellite_Award_for_Best_Film#Drama_(1996%E2%80%932009,_2018)").text

sa_soup = BeautifulSoup(sa_url,"lxml")
table_classes = {"class": ["wikitable"]}
sa_tables = sa_soup.find_all("table", table_classes)
sa_film = sa_tables[1]

sa_wintitles = []
links = sa_film.findAll("td")
for l in range(len(links)):
  if str(links[l]).startswith('<td style="background:#B0C4DE;"><i><b>'):
      sa_wintitles.append(html.unescape(str(links[l]).split("title=",1)[1].split(">",1)[1].split("<",1)[0]))

sa_winyears = []
sa_winyears.extend(np.arange(1996,2010))

sa_win = pd.DataFrame({'Film': sa_wintitles, 'Year': sa_winyears}).assign(Rater="SA").assign(Win=1)
sa_win = sa_win[["Rater","Film","Year","Win"]]

sa_nomtitles = []
links = sa_film.findAll("td")
for l in range(len(links)):
  if str(links[l]).startswith('<td><i>'):
      sa_nomtitles.append(html.unescape(str(links[l]).split("title=",1)[1].split(">",1)[1].split("<",1)[0]))

sa_nomyears = []
sa_nomyears.extend(np.repeat(1996,5))
sa_nomyears.extend(np.repeat(np.asarray([1997,1998]), 4))
sa_nomyears.extend(np.repeat(np.asarray([1999,2000]), 5))
sa_nomyears.extend(np.repeat(2001,4))
sa_nomyears.extend(np.repeat(2002,5))
sa_nomyears.extend(np.repeat(2003,6))
sa_nomyears.extend(np.repeat(np.asarray([2004,2005]), 5))
sa_nomyears.extend(np.repeat(2006,6))
sa_nomyears.extend(np.repeat(np.asarray([2007,2008,2009]), 5))
sa_nomyears.extend(np.repeat(2018,6))

sa_nom = pd.DataFrame({'Film': sa_nomtitles, 'Year': sa_nomyears}).assign(Rater="SA").assign(Win=-1)
sa_nom = sa_nom[["Rater","Film","Year","Win"]]

sa_frames = [sa_win, sa_nom]
sa = pd.concat(sa_frames).reset_index(drop=True)

sa.head()

sa.tail()

"""### Directors Guild of America Award for Outstanding Directing (1962-2018)"""

dga_url = requests.get("https://en.wikipedia.org/wiki/Directors_Guild_of_America_Award_for_Outstanding_Directing_%E2%80%93_Feature_Film").text

dga_soup = BeautifulSoup(dga_url,"lxml")
table_classes = {"class": ["wikitable"]}
dga_tables = dga_soup.find_all("table", table_classes)

dga_wintitles = []
for t in range(2,len(dga_tables)):
  links = dga_tables[t].findAll("td")
  for l in range(len(links)):
    if str(links[l]).startswith('<td style="background:#FAEB86;"><i><b>'):
      dga_wintitles.append(html.unescape(str(links[l]).split("title=",1)[1].split(">",1)[1].split("<",1)[0]))
dga_wintitles = dga_wintitles[2::]

dga_win = pd.DataFrame(dga_wintitles, columns=["Film"]).assign(Rater="DGA").assign(Win=1)
dga_win["Year"] = dga_win.index+1962
dga_win = dga_win[["Rater","Film","Year","Win"]]

dga_nomtitles = []
for t in range(2,len(dga_tables)):
  links = dga_tables[t].findAll("td")
  for l in range(len(links)):
    if str(links[l]).startswith('<td><i>'):
      dga_nomtitles.append(html.unescape(str(links[l]).split("title=",1)[1].split(">",1)[1].split("<",1)[0]))
dga_nomtitles = dga_nomtitles[25::]

dga_nomyears = []
for t in range(2,len(dga_tables)):
  links = dga_tables[t].findAll("td")
  for l in range(len(links)):
    if str(links[l]).startswith('<td rowspan='):
      if(l%2==0):
        rep_time = str(links[l]).split('"',1)[1].split('"',1)[0]
        for t in range(int(rep_time)-1):
          dga_nomyears.append(html.unescape(str(links[l]).split(">",1)[1].split("<",1)[0]))
dga_nomyears = dga_nomyears[25::]

dga_nom = pd.DataFrame({'Film': dga_nomtitles, 'Year': list(map(int,dga_nomyears))}).assign(Rater="DGA").assign(Win=-1)
dga_nom = dga_nom[["Rater","Film","Year","Win"]]

dga_frames = [dga_win, dga_nom]
dga = pd.concat(dga_frames).reset_index(drop=True)

dga.head()

dga.tail()

"""### BAFTA Award for Best Film (1962-2018)"""

bafta_url = requests.get("https://en.wikipedia.org/wiki/BAFTA_Award_for_Best_Film").text

bafta_soup = BeautifulSoup(bafta_url,"lxml")
table_classes = {"class": ["wikitable"]}
bafta_tables = bafta_soup.find_all("table", table_classes)

bafta_wintitles = []
for t in range(2,len(bafta_tables)):
  links = bafta_tables[t].findAll("td")
  for l in range(len(links)):
    if str(links[l]).startswith('<td style="background:#ccc;"><i><b>'):
      bafta_wintitles.append(html.unescape(str(links[l]).split("title=",1)[1].split(">",1)[1].split("<",1)[0]))
bafta_wintitles = bafta_wintitles[3::]

bafta_win = pd.DataFrame(bafta_wintitles, columns=["Film"]).assign(Rater="BAFTA").assign(Win=1)
bafta_win["Year"] = bafta_win.index+1962
bafta_win = bafta_win[["Rater","Film","Year","Win"]]

bafta_win.tail()

bafta_nomtitles = []
for t in range(2,len(bafta_tables)):
  links = bafta_tables[t].findAll("td")
  for l in range(len(links)):
    if str(links[l]).startswith('<td><i>'):
      bafta_nomtitles.append(html.unescape(str(links[l]).split("title=",1)[1].split(">",1)[1].split("<",1)[0]))
bafta_nomtitles = bafta_nomtitles[25::]

bafta_nomyears = []
year_ind = 1960
for t in range(2,len(bafta_tables)):
  links = bafta_tables[t].findAll("td")
  for l in range(len(links)):
    if str(links[l]).startswith('<td rowspan='):
      rep_time = str(links[l]).split('"',1)[1].split('"',1)[0]
      bafta_nomyears.extend(np.repeat(year_ind, int(rep_time)-1))
      year_ind += 1
bafta_nomyears = bafta_nomyears[26::]

bafta_nom = pd.DataFrame({'Film': bafta_nomtitles, 'Year': list(map(int,bafta_nomyears))}).assign(Rater="BAFTA").assign(Win=-1)
bafta_nom = bafta_nom[["Rater","Film","Year","Win"]]

bafta_frames = [bafta_win, bafta_nom]
bafta = pd.concat(bafta_frames).reset_index(drop=True)

bafta.head()

bafta.tail()

"""### Screen Actors Guild Award for Outstanding Performance by a Cast in a Motion Picture (1995-2018)"""

sag_url = requests.get("https://en.wikipedia.org/wiki/Screen_Actors_Guild_Award_for_Outstanding_Performance_by_a_Cast_in_a_Motion_Picture").text

sag_soup = BeautifulSoup(sag_url,"lxml")
table_classes = {"class": ["wikitable"]}
sag_tables = sag_soup.find_all("table", table_classes)

sag_wintitles = []
for t in range(len(sag_tables)):
  links = sag_tables[t].findAll("td")
  for l in range(len(links)):
    if str(links[l]).startswith('<td style="background:#FAEB86;"><i><b>'):
      sag_wintitles.append(html.unescape(str(links[l]).split("title=",1)[1].split(">",1)[1].split("<",1)[0]))

sag_win = pd.DataFrame(sag_wintitles, columns=["Film"]).assign(Rater="SAG").assign(Win=1)
sag_win["Year"] = sag_win.index+1995
sag_win = sag_win[["Rater","Film","Year","Win"]]

sag_nomtitles = []
for t in range(len(sag_tables)):
  links = sag_tables[t].findAll("td")
  for l in range(len(links)):
    if str(links[l]).startswith('<td><i>'):
      sag_nomtitles.append(html.unescape(str(links[l]).split("title=",1)[1].split(">",1)[1].split("<",1)[0]))

sag_nomyears = []
year_ind = 1995
for t in range(len(sag_tables)):
  links = sag_tables[t].findAll("td")
  for l in range(len(links)):
    if str(links[l]).startswith('<td align="center" rowspan='):
      rep_time = str(links[l]).split("rowspan",1)[1].split('"',1)[1].split('"',1)[0]
      sag_nomyears.extend(np.repeat(year_ind, int(rep_time)-1))
      year_ind += 1

sag_nom = pd.DataFrame({'Film': sag_nomtitles, 'Year': list(map(int,sag_nomyears))}).assign(Rater="SAG").assign(Win=-1)
sag_nom = sag_nom[["Rater","Film","Year","Win"]]

sag_frames = [sag_win, sag_nom]
sag = pd.concat(sag_frames).reset_index(drop=True)

sag.head()

sag.tail()

"""### Critics' Choice Movie Award for Best Picture (1995-2018)"""

cc_url = requests.get("https://en.wikipedia.org/wiki/Critics%27_Choice_Movie_Award_for_Best_Picture").text

cc_soup = BeautifulSoup(cc_url,"lxml")
cc_tables = cc_soup.find_all("ul")

cc_wintitles = []
for t in range(2,28):
  links = cc_tables[t].findAll("li")
  for l in range(len(links)):
    if str(links[l]).startswith('<li><b>'):
      cc_wintitles.append(html.unescape(str(links[l]).split("title=",1)[1].split(">",1)[1].split("<",1)[0]))

cc_win = pd.DataFrame(cc_wintitles, columns=["Film"]).assign(Rater="CC").assign(Win=1)
cc_win["Year"] = cc_win.index+1995
cc_win = cc_win[["Rater","Film","Year","Win"]]

cc_nomyears = []
cc_nomyears.extend(np.repeat(np.asarray([1996,1997,1998,1999]),9))
cc_nomyears.extend(np.repeat(2000, 10))
cc_nomyears.extend(np.repeat(np.asarray([2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014]), 9))
cc_nomyears.extend(np.repeat(2015,10))
cc_nomyears.extend(np.repeat(np.asarray([2016,2017,2018]),9))

cc_nomtitles = []
ccind = []
ccind.extend(np.arange(3,7))
ccind.extend(np.arange(8,18))
ccind.extend(np.arange(19,28))
for t in ccind:
  links = cc_tables[t].findAll("li")
  for l in range(len(links)):
    if str(links[l]).startswith('<li><i>'):
      cc_nomtitles.append(html.unescape(str(links[l]).split("title=",1)[1].split(">",1)[1].split("<",1)[0]))

cc_nom = pd.DataFrame({'Film': cc_nomtitles, 'Year': list(map(int,cc_nomyears))}).assign(Rater="CC").assign(Win=-1)
cc_nom = cc_nom[["Rater","Film","Year","Win"]]

cc_frames = [cc_win, cc_nom]
cc = pd.concat(cc_frames).reset_index(drop=True)

cc.head()

cc.tail()



"""### Full Data"""

all_awards = [oscars, nbra, sa, dga, bafta, sag, cc]
awards = pd.concat(all_awards).reset_index(drop=True)

awards.head()

awards.tail()

"""### Movie Metadata"""

movie_tag = pd.read_csv("movies.csv")

movie_tag.head()

movie_tag.loc[:,"title"]=[x.split('(')[0].strip(' \t\n\r') for x in movie_tag.loc[:,"title"]]

movie_tag.loc[:,"genres"]=[x.split('|')[0].strip(' \t\n\r') for x in movie_tag.loc[:,"genres"]]

movie_tag = movie_tag >> drop(X.movieId) >> rename(Film=X.title, Genres=X.genres)

movie_tag.head()

movie_tag = movie_tag.drop_duplicates(subset=['Film'],keep='first')

award_tag = pd.merge(awards,movie_tag,on="Film",how='left')

assert(awards.shape[0] == award_tag.shape[0])

"""### Write File"""

award_tag.to_csv("award_tag.csv", index=False)

from google.colab import files
files.download("award_tag.csv")

"""### Oscar Test Set"""

oscar_test = (oscar_data >> mask(X.category=="BEST PICTURE") 
                >> mask(X.year >= 2003)
                >> drop(["category"]) 
                >> rename(Year=X.year,Film=X.entity, Win=X.winner) )
booleanDictionary = {True: 'True', False: 'False'}
oscar_test["Win"] = oscar_test["Win"].map(booleanDictionary)
di_oscar = {"True": 1, "False": -1}
oscar_test = oscar_test.replace({"Win": di_oscar})
oscar_test = oscar_test.assign(Rater="Oscars")[["Rater","Film","Year","Win"]].reset_index(drop=True)

oscar_test.tail()

oscar_test_tag = pd.merge(oscar_test,movie_tag,on="Film",how='left')

oscar_test_tag.tail()

assert(oscar_test.shape[0] == oscar_test_tag.shape[0])

"""### Write test file"""

oscar_test_tag.to_csv("oscar_test_tag.csv", index=False)
from google.colab import files
files.download("oscar_test_tag.csv")

